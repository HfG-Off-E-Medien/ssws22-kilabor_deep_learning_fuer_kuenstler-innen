{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.optim import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_neurons,\n",
    "        n_neurons_hidden_layer_1,\n",
    "        n_neurons_output_layer = 1\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        ''' Model parameters '''\n",
    "        self.layer1 = nn.Linear(\n",
    "            n_input_neurons,\n",
    "            n_neurons_hidden_layer_1)\n",
    "        \n",
    "        self.head = nn.Linear(\n",
    "            n_neurons_hidden_layer_1,\n",
    "            n_neurons_output_layer)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = torch.flatten(img, start_dim=1)\n",
    "        x = self.layer1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.head(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "# Dummy dataset\n",
    "noise_ratio = 0.1\n",
    "n = 100\n",
    "n_input_neurons = 10\n",
    "\n",
    "train_a = torch.zeros(n, n_input_neurons)\n",
    "train_a += torch.randn_like(train_a) * noise_ratio\n",
    "\n",
    "train_b = torch.ones(n, n_input_neurons)\n",
    "train_b += torch.randn_like(train_b) * noise_ratio\n",
    "\n",
    "labels_a = torch.zeros(n, 1)\n",
    "labels_b = torch.ones(n, 1)\n",
    "\n",
    "eval_split = 20\n",
    "train_set = torch.cat([train_a[:-eval_split], train_b[:-eval_split]], axis=0)\n",
    "eval_set = torch.cat([train_a[-eval_split:], train_b[-eval_split:]], axis=0)\n",
    "train_labels = torch.cat([labels_a[:-eval_split], labels_b[:-eval_split]], axis=0)\n",
    "eval_labels = torch.cat([labels_a[-eval_split:], labels_b[-eval_split:]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Model(n_input_neurons, 200, 1).to(device)\n",
    "opt = SGD(M.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02620432]]\n",
      "[[0.02578765]]\n",
      "[[0.02538165]]\n",
      "[[0.02498597]]\n",
      "[[0.02460027]]\n",
      "[[0.0242242]]\n",
      "[[0.02385744]]\n",
      "[[0.02349972]]\n",
      "[[0.02315071]]\n",
      "[[0.02281014]]\n",
      "[[0.02247773]]\n",
      "[[0.02215323]]\n",
      "[[0.0218364]]\n",
      "[[0.02152696]]\n",
      "[[0.02122474]]\n",
      "[[0.02092945]]\n",
      "[[0.02064093]]\n",
      "[[0.02035894]]\n",
      "[[0.02008329]]\n",
      "[[0.01981381]]\n",
      "[[0.01955029]]\n",
      "[[0.01929255]]\n",
      "[[0.01904044]]\n",
      "[[0.01879378]]\n",
      "[[0.01855241]]\n",
      "[[0.01831621]]\n",
      "[[0.01808497]]\n",
      "[[0.01785861]]\n",
      "[[0.01763695]]\n",
      "[[0.01741988]]\n",
      "[[0.01720726]]\n",
      "[[0.01699898]]\n",
      "[[0.01679491]]\n",
      "[[0.01659493]]\n",
      "[[0.01639894]]\n",
      "[[0.01620683]]\n",
      "[[0.01601849]]\n",
      "[[0.01583382]]\n",
      "[[0.01565273]]\n",
      "[[0.01547512]]\n",
      "[[0.01530088]]\n",
      "[[0.01512996]]\n",
      "[[0.01496226]]\n",
      "[[0.01479768]]\n",
      "[[0.01463618]]\n",
      "[[0.01447764]]\n",
      "[[0.014322]]\n",
      "[[0.0141692]]\n",
      "[[0.01401914]]\n",
      "[[0.0138718]]\n",
      "[[0.01372706]]\n",
      "[[0.0135849]]\n",
      "[[0.01344523]]\n",
      "[[0.01330799]]\n",
      "[[0.01317314]]\n",
      "[[0.01304061]]\n",
      "[[0.01291036]]\n",
      "[[0.01278232]]\n",
      "[[0.01265645]]\n",
      "[[0.01253267]]\n",
      "[[0.01241098]]\n",
      "[[0.0122913]]\n",
      "[[0.01217359]]\n",
      "[[0.01205781]]\n",
      "[[0.0119439]]\n",
      "[[0.01183185]]\n",
      "[[0.01172159]]\n",
      "[[0.01161309]]\n",
      "[[0.01150631]]\n",
      "[[0.01140123]]\n",
      "[[0.01129778]]\n",
      "[[0.01119595]]\n",
      "[[0.01109569]]\n",
      "[[0.01099698]]\n",
      "[[0.01089978]]\n",
      "[[0.01080406]]\n",
      "[[0.01070978]]\n",
      "[[0.01061692]]\n",
      "[[0.01052544]]\n",
      "[[0.01043533]]\n",
      "[[0.01034656]]\n",
      "[[0.01025908]]\n",
      "[[0.01017288]]\n",
      "[[0.01008793]]\n",
      "[[0.0100042]]\n",
      "[[0.00992168]]\n",
      "[[0.00984032]]\n",
      "[[0.00976014]]\n",
      "[[0.00968108]]\n",
      "[[0.00960313]]\n",
      "[[0.00952627]]\n",
      "[[0.00945048]]\n",
      "[[0.00937572]]\n",
      "[[0.00930201]]\n",
      "[[0.00922929]]\n",
      "[[0.00915756]]\n",
      "[[0.0090868]]\n",
      "[[0.00901698]]\n",
      "[[0.0089481]]\n",
      "[[0.00888014]]\n"
     ]
    }
   ],
   "source": [
    "loss_epochs = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for x, y in zip(train_set, train_labels):\n",
    "        opt.zero_grad()\n",
    "        x = torch.unsqueeze(x, 0)\n",
    "        y = torch.unsqueeze(y, 0)\n",
    "        pred = M(x)\n",
    "        loss = (pred - y)**2\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss += loss.detach().numpy()\n",
    "    epoch_loss /= len(train_set)\n",
    "    print(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = torch.rand(16,10,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10, 10, 1])\n",
      "torch.Size([16, 100])\n",
      "torch.Size([16, 200])\n",
      "torch.Size([16, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2659],\n",
       "        [0.3368],\n",
       "        [0.4122],\n",
       "        [0.2110],\n",
       "        [0.4664],\n",
       "        [0.1938],\n",
       "        [0.3502],\n",
       "        [0.4654],\n",
       "        [0.3905],\n",
       "        [0.1380],\n",
       "        [0.4062],\n",
       "        [0.3217],\n",
       "        [0.4408],\n",
       "        [0.3648],\n",
       "        [0.3889],\n",
       "        [0.2295]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = torch.rand((16,10,10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mymodel(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1557],\n",
       "        [-0.1651],\n",
       "        [-0.1731],\n",
       "        [-0.4020],\n",
       "        [-0.2045],\n",
       "        [-0.2229],\n",
       "        [-0.0085],\n",
       "        [-0.2376],\n",
       "        [-0.1434],\n",
       "        [-0.1054],\n",
       "        [-0.2459],\n",
       "        [ 0.0123],\n",
       "        [-0.3041],\n",
       "        [-0.0331],\n",
       "        [-0.1118],\n",
       "        [-0.1587]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 30000])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(img_batch, start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49152,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = layer1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 100])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('kilab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae0eab63ca51c069bcc14e75e2c7d6e0afcd48699d3e73932dc01cda641bc4dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
